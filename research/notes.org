#+TITLE: Notes / Research on CPU-Scheduling
#+AUTHOR: Mark Krutzler

* Sources Checklist:
** [1/4] OStep
*** [X] cpu-sched.pdf
*** [ ] cpu-sched-mlfq.pdf
*** [ ] cpu-sched-lottery.pdf
*** [ ] cpu-sched-multi.pdf
** [0/1] Computer Scheduling Methods and their Countermeasures
*** [ ] cpu-sched.pdf
** [0/2] Lottery Scheduling
*** [ ] phd-mit-tr667.pdf
*** [ ] waldspurger.pdf
** [0/1] Adjusting Parameters using Machine Learning
*** [ ] ml.pdf
** [0/1] 2.6 CFS
*** [ ] inside-cfs.pdf
** [0/1] Solaris Scheduling
*** [ ]  notes-solaris.pdf
** [0/1] ULE vs CFS
*** [ ] atc18-bouron.pdf
* Basics (OStep)
** Introduction (Chapter 7)
Scheduling is not a low level mechanism but a high level policy/disciplines.
We need to make simplifying assumptions of the workload:
1. Each job runs for the same amount of time
2. All jobs arrive at the same time.
3. Once started, each job runs to completion
4. All jobs only use the CPU (no I/O)
5. The run-time of each job is known.
These rules will be eased over time until we get a fully functioning policy.
Of course the more you know the easier it is to schedule.
*** Metrics
The fundamental question is: How to we measure the "efficiency" or the "quality" of the scheduler?
You can measure performance or fairness. Here are ways to measure performance:
- turnaround time
  - Calculated as:
    $T_{turnaround} = T_{completion} - T_{arrival}$
    For us $T_{arrival} = 0$, because of simplification 1. (can be neglected later)
- response time: measures the frustration of the user, while looking at the spinning ball
  - Calculated as:
    $T_{response} = T_{firstrun} - T_{arrival}$
    - For modern computers, it is essential that this is kept at a minimum
*** First In, First Out (FIFO) / First Come, First Served (FCFS)
- Most basic scheduling policy
- Given our simplification it works really well and is easy to implement
- However after relaxing assumption 1, it will perform poorly if a huge process gets infront of many small ones
  - This is the so called *convoy effect*
  - It is like if you're at waiting in line to pay and before you have a family of five with two full carts: annoying
*** Shortest Job First (SJF)
- The shortest job is run first
  - non-preemptive: runs a process until finish
  - preemptive: can stop and perform a context switch
- If the smaller tasks arrive later (by relaxing assumption 2), then we face the same problem as before. (due to this algorithm can't perform a context switch / is non-preemptive)
*** Shortest Time-to-Completion (STCF) / Preemptive Shortest Job First (PSJF)
- This policy requires that rule 3 is ignored.
- This is the preemptive version of SJF.
- It updates, whenever a new job arrives or one is finished
*** Round Robin (RR) / time-slicing
- this policy runs each job for a specified "time slice" / "scheduling quantum" (introducing a variable)
- general technique is called "amortization".
- The shorter the time slice, the more responsive the system, however context switching costs CPU time aswell, so you'll need to balance out
- RR is one of the worst policies for turnaround time
- It gives up performance for fairness
*** Relaxing Assumptions 4 & 5
**** assumption 4
- If a job waits for I/O than it is in a state called "blocked"
- While a job is waiting for I/O, the CPU can be passed onto somebodye else: "overlapping"
**** assumption 5
- we usually have no idea how long a job will take
- This actually breaks most of our policies, because they all rely on knowing the length of the job (except RR)
- Solution: Multi-Level Feedback Queue (MLFQ) $\Rightarrow$ See next Chapter
** Multi-Level Feedback Queue (Chapter 8)
- One of the most known Policies (Turning Awarded)
- It tries to:
  - optimize turn around time (without knowing the length of the job)
  - minimize response time
*** (Basic) Rules of MLFQ
- There are multiple queues and each has their priority level. (higher priority is preferred when switching)
- If multiple jobs are on the same priority than RR (Round Robin) is used
- Priorities can change over time.
- Assume that if a job is resource intensive than it will stay as such. (The history of the job determines the future)
*** Changing Priority
- Depending on the CPU time usage, the priority changes
- "allotment": time that a job can spend at a given priority before demotion.
*** Priority Boost
- to counter starvation of longer jobs every now and then all of the jobs are put into the priority queue
- also this counters the fact that some programs might start non interactively and than turn into interactive (you know what I mean)
*** "Better Accounting" (Anti gaming)
- to prevent people from abusing the allotment method and game the CPU, we need to update rule 4:
- previous:
  a. If a job uses up its allotment while running, its priority is reduced
  b. If a job gives up the CPU before the allotment is up, it stays at the same priority
- new:
  Once a job uses up its time allotment at a given level, its priority is reduced
*** Summary of Rules (Copied out of the book)
1. If Priority (A) > Priority (B) $\Rightarrow$ A runs & B doesn't
2. If Priority (A) = Priority (B) $\Rightarrow$ A & B run in RR
3. When a job enters the system, it is placed at the highest priority
4. Once a job uses up its time allotment at a given level, its priority is reduced
5. After some period S, move all the jobs in the system to the topmost queue
*** Voo-Doo Constants
These constants heavily change how effective the MLFQ is:
- scheduling quantum (RR)
- amount of queues
- when to priority boost
- allotment (could change in every priority queue)
* Computer Scheduling Methods and their Countermeasures
* Lottery Scheduling
* Adjusting Parameters using Machine Learning
* Examples
** Linux 2.6 Fair Scheduler
** Solaris Scheduling
** Ule vs Cfs
