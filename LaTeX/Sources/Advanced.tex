\chapter{Predicting the Future based on the Past}

\section{Idea}

The first policy we look at is formerly called Multi-Level Feedback Queue or MLFQ short. The create Fernando J. Corbat√≥ recieved a Turning Awaard for it in 1990. 
As the title already says, this policy tries to predict the future behaviour of the processes based on the past.
A job can be generally act in two ways.
Either it is a resources intensive crunching problem (think about exporting a video or compiling code) or it is a program, which needs quick response time (think about your text editor).
In reality most jobs jump between these two states.
We usually want to give the response based processes priority, because that is what the user interacts with and it is here that he primarily feels a delay.

The policy is based on multiple queues, which have each different priorities.
Each process gets assigned to a queue. There are however not set in stone
Based on the reasons above we want to assume that a new process is responsive, because in the worst case scenario, we need to just demote the non-responsive ones.
If however a process turns out to be interactive, than the user does not feel any lag. 
Each process can run a certain amount of time (also called allotment time) before it is deemed as unworthy of the current priority.
If the allotment is used up the process get demoted into a queue below.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{Assets/MLFQ-Example-1.pdf}
    \caption{Simple working of MLFQ}
    \label{fig:mlfq-example-1}
\end{figure}


As you can see in figure \ref{fig:mlfq-example-1} the process one gets demoted after a while.
Also the lower the queue is, the higher the allotment time. 
This is because we hope that all of the responsive focused finish before demoting.
Once these are filtered out we have only resource heavy tasks left.
These require more time anyways, so the allotment time is stretched out.

